#!/usr/bin/env python3
"""
Gemini Counsel - Gemini AIì—ê²Œ ì½”ë”© ì¡°ì–¸ì„ êµ¬í•˜ëŠ” ìŠ¤í‚¬

Usage:
    counsel.py "ì§ˆë¬¸"
    counsel.py "ì§ˆë¬¸" --context "ì½”ë“œ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸"
    counsel.py "ì§ˆë¬¸" --file path/to/file.py
    counsel.py "ì§ˆë¬¸" --model gemini-2.5-pro
"""

import argparse
import json
import os
import sys
from pathlib import Path

# ì „ì—­ venvì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ dotenv ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv(Path.home() / ".claude" / ".env")
except ImportError:
    pass  # dotenv ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ê¸°

import urllib.request
import urllib.error


def call_gemini(prompt: str, model: str = "gemini-3-pro-preview") -> str:
    """Gemini API í˜¸ì¶œ"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return "âŒ Error: GEMINI_API_KEY not found in ~/.claude/.env"

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì‚¬ìš©ì ì§ˆë¬¸
    system_prompt = """ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
ì½”ë“œ ë¦¬ë·°, ì•„í‚¤í…ì²˜ ì¡°ì–¸, ë””ë²„ê¹… íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë‹µë³€ì€ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë˜, ì½”ë“œì™€ ê¸°ìˆ  ìš©ì–´ëŠ” ì›ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."""

    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [{"text": f"{system_prompt}\n\n---\n\n{prompt}"}]
            }
        ],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 8192,
        }
    }

    req = urllib.request.Request(
        url,
        data=json.dumps(payload).encode("utf-8"),
        headers={"Content-Type": "application/json"},
        method="POST"
    )

    try:
        with urllib.request.urlopen(req, timeout=60) as response:
            result = json.loads(response.read().decode("utf-8"))

            # ì‘ë‹µ íŒŒì‹±
            if "candidates" in result and len(result["candidates"]) > 0:
                candidate = result["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    text = candidate["content"]["parts"][0].get("text", "")
                    return text

            return f"âŒ Unexpected response format: {json.dumps(result, indent=2)}"

    except urllib.error.HTTPError as e:
        error_body = e.read().decode("utf-8") if e.fp else ""
        return f"âŒ HTTP Error {e.code}: {error_body}"
    except urllib.error.URLError as e:
        return f"âŒ URL Error: {e.reason}"
    except Exception as e:
        return f"âŒ Error: {str(e)}"


def main():
    parser = argparse.ArgumentParser(description="Gemini AIì—ê²Œ ì½”ë”© ì¡°ì–¸ì„ êµ¬í•©ë‹ˆë‹¤")
    parser.add_argument("question", help="ì§ˆë¬¸ ë‚´ìš©")
    parser.add_argument("--context", "-c", help="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì½”ë“œ ë“±)")
    parser.add_argument("--file", "-f", help="ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model", "-m", default="gemini-3-pro-preview",
                        help="ì‚¬ìš©í•  ëª¨ë¸ (default: gemini-3-pro-preview)")

    args = parser.parse_args()

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = args.question

    if args.file:
        file_path = Path(args.file)
        if file_path.exists():
            content = file_path.read_text(encoding="utf-8")
            prompt = f"{args.question}\n\n### íŒŒì¼: {args.file}\n```\n{content}\n```"
        else:
            print(f"âŒ File not found: {args.file}", file=sys.stderr)
            sys.exit(1)
    elif args.context:
        prompt = f"{args.question}\n\n### ì»¨í…ìŠ¤íŠ¸\n```\n{args.context}\n```"

    # Gemini í˜¸ì¶œ
    print(f"ğŸ’ **Geminiì˜ ì¡°ì–¸:** (model: `{args.model}`)\n")
    response = call_gemini(prompt, args.model)
    print(response)


if __name__ == "__main__":
    main()
